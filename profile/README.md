# Vision-Language @ CAMP, TUM

Welcome to the Vision-Language Group of the Chair for [Computer-Aided Medical Procedures & Augmented Reality (CAMP)](https://www.cs.cit.tum.de/camp) of [Prof. Dr. Nassir Navab](https://www.cs.cit.tum.de/camp/members/cv-nassir-navab/nassir-navab/) at the [Technical University of Munich (TUM)](https://www.tum.de/). Our team investigates the synergy between natural language processing (NLP), computer vision, and deep learning, particularly in the medical field.

We focus on creating solutions that analyze and interpret medical images and articulate these findings clearly for medical professionals, thereby enhancing diagnosis accuracy and patient outcomes. Our research spans across areas like radiology report generation, medical visual question answering (VQA), semantic explanations, and structured reporting.

## Recent works

| Year | Title | Authors | Publication | Code |
|-----------------|-------|---------|----------|---|
| 2023 | [RaDialog: A Large Vision-Language Model for Radiology Report Generation and Conversational Assistance](https://arxiv.org/abs/2311.18681)) | Chantal Pellegrini, Ege Ã–zsoy, Benjamin Busam, Nassir Navab, Matthias Keicher | Arxiv | [![](https://img.shields.io/badge/RaDialog-grey?logo=github)](https://github.com/ChantalMP/RaDialog) |
| 2023 | [Rad-ReStruct: A Novel VQA Benchmark and Method for Structured Radiology Reporting](https://arxiv.org/abs/2307.05766) | Chantal Pellegrini, Matthias Keicher, Ege Ã–zsoy, Nassir Navab | [MICCAI 2023](https://conferences.miccai.org/2023/) | [![](https://img.shields.io/badge/RadReStruct-grey?logo=github)](https://github.com/ChantalMP/Rad-ReStruct) |
| 2023 | [Xplainer: From X-Ray Observations to Explainable Zero-Shot Diagnosis](https://arxiv.org/pdf/2303.13391.pdf) | Chantal Pellegrini, Matthias Keicher, Ege Ã–zsoy, Petra Jiraskova, Rickmer Braren, Nassir Navab | [MICCAI 2023](https://conferences.miccai.org/2023/) | [![](https://img.shields.io/badge/Xplainer-grey?logo=github)](https://github.com/ChantalMP/Xplainer) |
| 2023 | [Prior-RadGraphFormer: A Prior-Knowledge-Enhanced Transformer for Generating Radiology Graphs from X-Rays](https://arxiv.org/abs/2303.13818) | Yiheng Xiong, Jingsong Liu, Kamilia Zaripova, Sahand Sharifzadeh, Matthias Keicher, Nassir Navab | [GRAIL @ MICCAI 2023](https://grail-miccai.github.io/#program) | [![](https://img.shields.io/badge/RadGraphFormer-grey?logo=github)](https://github.com/xiongyiheng/Prior-RadGraphFormer) |
| 2022 | [FlexR: Few-shot Classification with Language Embeddings for Structured Reporting of Chest X-rays](https://arxiv.org/abs/2203.15723) | Matthias Keicher, Kamilia Zaripova, Tobias Czempiel, Kristina Mach, Ashkan Khakzar, Nassir Navab | [MIDL 2023](https://2023.midl.io/) | [![](https://img.shields.io/badge/FlexR-grey?logo=github)](https://github.com/mkeicher/FlexR) |

<!--

**Here are some ideas to get you started:**

ðŸ™‹â€â™€ï¸ A short introduction - what is your organization all about?
ðŸŒˆ Contribution guidelines - how can the community get involved?
ðŸ‘©â€ðŸ’» Useful resources - where can the community find your docs? Is there anything else the community should know?
ðŸ¿ Fun facts - what does your team eat for breakfast?
ðŸ§™ Remember, you can do mighty things with the power of [Markdown](https://docs.github.com/github/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax)
-->
